# neural_network_performance_guide_2
Materials for RCC workshop "Performance Guidelines of Neural Network Models: Perspective of Operation Efficiency"
### Abstract
In addition to model accuracy (which some refer to as task performance) addressed in the previous workshop, the perfomrance of operation speed is essential. Hyper-parameter selection impacts the performance of various types of neural network layers commonly used in state-of-the-art deep learning applications. In this workshop, we compare operation performance with two metrics: duration (in msec) and throughput (in FLOPs). We cover sevral common neural network operations, each of which the operation performance is briefly described, as well as the impact of each configuration parameter (hyperparameter) on performance.  It focuses on GPUs that provide Tensor Core acceleration for deep learning.

### Objectives:
During the workshop participants will be able to:<br>
* Understand performance
* How to measure (operation speed) performance
* Distinguish the difference between math-limited and bandwidth-limited operations
* How to choose parameters to optimize execution efficiency
* Apply general recommendations to particular routines

### Level: 
  Intermediate
  
  
### Duration: 
  2.5 hours
  
  
### Prerequisites: 
All participants are expected to bring a laptop with a Mac, Linux, or Windows operating system that they have administrative privileges on.  This workshop assumes participants possess prior programming experience, particularly in Python and Jupyter Notebook. An RCC account is not required
